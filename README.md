# Birds vs Drones Detection and Tracking System

## ğŸŒ Live Demo
Try out our application: [Birds vs Drones Detection System Demo](https://aman-vishwakarma-bird-vs-drone-detection-and-tracking.streamlit.app/)

## ğŸš€ Project Overview
A comprehensive computer vision application for detecting and tracking birds and drones using YOLOv8. This system employs advanced deep learning techniques with a focus on modularity, error handling, and robust logging capabilities.

## ğŸ›  Key Features
- Real-time bird and drone detection
- Comprehensive data augmentation pipeline
- Advanced model evaluation metrics
- Object tracking capabilities
- Robust error handling and logging
- Streamlit-based user interface
- Support for both image and video processing

## ğŸ“‚ Project Structure
```
birds_vs_drones_detection_and_tracking/
â”œâ”€â”€ .env                        # Environment variables configuration
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ app.py                     # Streamlit web application
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ setup.py                  # Package installation configuration
â”œâ”€â”€ yolov8n.pt                # YOLOv8 nano pre-trained weights
â”œâ”€â”€ augmented_data/           # Directory for augmented training data
â”œâ”€â”€ data/                     # Dataset directory
â”‚   â”œâ”€â”€ README.dataset.txt    # Dataset documentation
â”‚   â”œâ”€â”€ README.roboflow.txt   # Roboflow dataset information
â”‚   â”œâ”€â”€ data.yaml            # Dataset configuration
â”‚   â”œâ”€â”€ train/               # Training dataset
â”‚   â”œâ”€â”€ valid/               # Validation dataset
â”‚   â””â”€â”€ test/                # Test dataset
â”œâ”€â”€ research/                 # Research and development notebooks
â”‚   â”œâ”€â”€ edith-defence-system-v-0.0.1.ipynb
â”‚   â””â”€â”€ edith-defence-system-v-0.0.2.ipynb
â”œâ”€â”€ runs/                     # Training runs and model artifacts
â””â”€â”€ src/                     # Source code
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ components/          # Core components
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ data_augmentation.py    # Data augmentation pipeline
    â”‚   â””â”€â”€ download_dataset.py     # Dataset download utilities
    â”œâ”€â”€ pipeline/            # Training and inference pipelines
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ evaluation.py           # Model evaluation scripts
    â”‚   â”œâ”€â”€ prediction.py           # Prediction pipeline
    â”‚   â””â”€â”€ training-v-0.0.1.py     # Training pipeline
    â”œâ”€â”€ custom_exception.py  # Custom exception handling
    â””â”€â”€ logger.py           # Logging infrastructure
```

### ğŸ“ Directory Details

#### Core Directories
- **src/**: Contains all source code and core functionality
  - **components/**: Core processing modules
  - **pipeline/**: Training and inference pipelines
  - **custom_exception.py**: Exception handling system
  - **logger.py**: Logging infrastructure

#### Data Management
- **data/**: Contains dataset files and configuration
  - Organized into train, validation, and test sets
  - Includes dataset documentation and configuration
- **augmented_data/**: Stores augmented training data
  - Generated by data_augmentation.py
  - Used for model training enhancement

#### Model Artifacts
- **runs/**: Contains training outputs
  - Model weights
  - Training logs
  - Evaluation metrics
- **yolov8n.pt**: Pre-trained YOLOv8 nano weights

#### Development
- **research/**: Jupyter notebooks for R&D
  - Version 0.0.1 and 0.0.2 development notebooks
  - Experimental features and analysis

#### Configuration
- **.env**: Environment variables
- **requirements.txt**: Python dependencies
- **.gitignore**: Git ignore patterns

## ğŸ”§ Installation and Setup

1. Clone the repository:
```bash
git clone https://github.com/Aman-Vishwakarma1729/Birds-vs-Drones-Detection-and-Tracking-System.git
cd Birds-vs-Drones-Detection-and-Tracking-System
```

2. Create and activate a virtual environment:
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
```

3. Install the package in development mode:
```bash
pip install -e .
```

4. Set up environment variables:
Create a `.env` file in the project root with your Roboflow API key:
```
ROBOFLOW_API_KEY=your_api_key_here
```

5. Download and setup the dataset:
```bash
python -m src.components.download_dataset
```
This will:
- Download the dataset from Roboflow
- Rename the downloaded folder to 'data'
- Update data.yaml with correct paths
- Create necessary directory structure:
  ```
  data/
  â”œâ”€â”€ data.yaml          # Dataset configuration
  â”œâ”€â”€ train/
  â”‚   â”œâ”€â”€ images/       # Training images
  â”‚   â””â”€â”€ labels/       # Training labels
  â”œâ”€â”€ valid/
  â”‚   â”œâ”€â”€ images/       # Validation images
  â”‚   â””â”€â”€ labels/       # Validation labels
  â””â”€â”€ test/
      â”œâ”€â”€ images/       # Test images
      â””â”€â”€ labels/       # Test labels
  ```

## ğŸ”§ Component Details

### Core Components
1. **Data Augmentation** (`components/data_augmentation.py`)
   - Implements advanced augmentation techniques
   - Supports various transformation strategies
   - Handles batch processing of images

2. **Dataset Management** (`components/download_dataset.py`)
   - Manages dataset download from Roboflow
   - Handles data validation and verification
   - Implements error handling for download process

3. **Model Pipeline**
   - **Evaluation** (`pipeline/evaluation.py`): Comprehensive model evaluation metrics
   - **Prediction** (`pipeline/prediction.py`): Real-time inference pipeline
   - **Training** (`pipeline/training-v-0.0.1.py`): YOLOv8 training workflow

### Infrastructure
1. **Exception Handling** (`custom_exception.py`)
   - Custom exception classes for different error types
   - Detailed error tracking with file and line information
   - Specialized exceptions for model, data, and prediction errors

2. **Logging System** (`logger.py`)
   - Comprehensive logging infrastructure
   - Multiple logger categories (model, data, prediction)
   - Timestamped log files and console output

## ğŸ“¦ Dependencies
- ultralytics==8.0.0
- torch>=2.0.0
- opencv-python>=4.7.0
- streamlit>=1.24.0
- albumentations>=1.3.1
- python-dotenv>=1.0.0
- numpy>=1.24.0
- matplotlib>=3.7.1
- pandas>=2.0.0

## ğŸš€ Getting Started

1. **Environment Setup**
   ```bash
   # Create and activate virtual environment
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   source .venv/bin/activate  # Linux/Mac
   ```

2. **Installation**
   There are two ways to install the project dependencies:

   a) Using requirements.txt:
   ```bash
   pip install -r requirements.txt
   ```

   b) Using setup.py (recommended for development):
   ```bash
   pip install -e .
   ```
   This will install the project in development mode, making it easier to modify the code without reinstalling.

   The setup.py file includes the following dependencies:
   - ultralytics (YOLOv8)
   - numpy
   - matplotlib
   - pandas
   - opencv-python
   - streamlit
   - albumentations
   - python-dotenv

3. **Configure Environment Variables**
   - Create a `.env` file in the project root
   - Add your Roboflow API key:
     ```
     ROBOFLOW_API_KEY=your_api_key_here
     ```

4. **Download Dataset**
   ```bash
   python src/components/download_dataset.py
   ```

5. **Run Training**
   ```bash
   python src/pipeline/training-v-0.0.1.py
   ```

6. **Launch Web Interface**
   ```bash
   streamlit run app.py
   ```

## ğŸ” Model Configuration
- Base Model: YOLOv8 Nano
- Classes: Bird, Drone
- Default Confidence Threshold: 0.25
- IoU Threshold Range: 0.45-0.5

## ğŸ“Š Evaluation Metrics
- mAP50
- mAP50-95
- Precision
- Recall
- F1-score

## ğŸ” Security Considerations
- API keys stored in `.env` file
- Secure file handling implementation
- Input validation for all user inputs
- Comprehensive error logging

## ğŸš§ Future Improvements
1. Enhanced small object detection capabilities
2. Implementation of advanced tracking algorithms
3. Real-time camera input support
4. Extended dataset diversity
5. Edge device deployment optimizations
6. Comprehensive unit test coverage

## ğŸ‘¥ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.
